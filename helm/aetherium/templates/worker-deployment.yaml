{{- if and .Values.worker.enabled (eq .Values.worker.kind "Deployment") }}
apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ include "aetherium.fullname" . }}-worker
  labels:
    {{- include "aetherium.worker.labels" . | nindent 4 }}
spec:
  replicas: {{ .Values.worker.replicaCount | default 1 }}
  selector:
    matchLabels:
      {{- include "aetherium.worker.selectorLabels" . | nindent 6 }}
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 0
  template:
    metadata:
      labels:
        {{- include "aetherium.worker.selectorLabels" . | nindent 8 }}
      annotations:
        checksum/config: {{ include (print $.Template.BasePath "/configmap.yaml") . | sha256sum }}
        checksum/secret: {{ include (print $.Template.BasePath "/secrets.yaml") . | sha256sum }}
    spec:
      {{- include "aetherium.imagePullSecrets" . | nindent 6 }}
      serviceAccountName: {{ include "aetherium.serviceAccountName" . }}
      {{- if .Values.worker.hostNetwork }}
      hostNetwork: true
      dnsPolicy: {{ .Values.worker.dnsPolicy | default "ClusterFirstWithHostNet" }}
      {{- end }}

      # Init container to prepare rootfs template with fc-agent
      initContainers:
        - name: prepare-rootfs
          image: {{ include "aetherium.worker.image" . }}
          imagePullPolicy: {{ .Values.worker.image.pullPolicy | default .Values.global.imagePullPolicy }}
          command:
            - /bin/sh
            - -c
            - |
              set -e
              echo "=== Aetherium Worker Initialization ==="
              echo ""

              # 1. Verify KVM
              echo "1. Checking KVM..."
              if [ ! -e /dev/kvm ]; then
                echo "ERROR: /dev/kvm not found - KVM not available"
                exit 1
              fi
              echo "   ✓ KVM device available"

              # 2. Verify kernel
              echo "2. Checking Firecracker kernel..."
              if [ ! -f /var/firecracker/vmlinux ]; then
                echo "ERROR: Kernel not found at /var/firecracker/vmlinux"
                exit 1
              fi
              echo "   ✓ Kernel image found"

              # 3. Verify base rootfs exists
              echo "3. Checking base rootfs..."
              if [ ! -f /var/firecracker/rootfs.ext4 ]; then
                echo "ERROR: Base rootfs not found at /var/firecracker/rootfs.ext4"
                exit 1
              fi
              echo "   ✓ Base rootfs image found"

              # 4. Prepare rootfs template (per-VM isolation)
              echo "4. Preparing rootfs template..."

              # Check if template already exists
              if [ ! -f /var/firecracker/rootfs-template.ext4 ]; then
                echo "   Creating rootfs template from base..."
                cp /var/firecracker/rootfs.ext4 /var/firecracker/rootfs-template.ext4
                echo "   ✓ Template created"
              else
                echo "   ✓ Template already exists"
              fi

              # 5. Install fc-agent in template (idempotent)
              echo "5. Installing fc-agent in template..."
              MOUNT_POINT="/tmp/rootfs-mount"
              mkdir -p "$MOUNT_POINT"
              mount -o loop /var/firecracker/rootfs-template.ext4 "$MOUNT_POINT"

              if [ -f "$MOUNT_POINT/usr/local/bin/fc-agent" ] && \
                 [ -f "$MOUNT_POINT/etc/systemd/system/fc-agent.service" ]; then
                echo "   ✓ fc-agent already installed in template"
              else
                echo "   Installing fc-agent..."

                # Copy fc-agent binary from this container
                cp /usr/local/bin/fc-agent "$MOUNT_POINT/usr/local/bin/fc-agent"
                chmod +x "$MOUNT_POINT/usr/local/bin/fc-agent"

                # Create systemd service
                cat > "$MOUNT_POINT/etc/systemd/system/fc-agent.service" <<'EOF'
              [Unit]
              Description=Firecracker Agent
              After=network.target

              [Service]
              Type=simple
              ExecStart=/usr/local/bin/fc-agent
              Restart=always
              RestartSec=3
              StandardOutput=journal
              StandardError=journal

              [Install]
              WantedBy=multi-user.target
              EOF

                # Enable service
                mkdir -p "$MOUNT_POINT/etc/systemd/system/multi-user.target.wants"
                ln -sf /etc/systemd/system/fc-agent.service \
                  "$MOUNT_POINT/etc/systemd/system/multi-user.target.wants/fc-agent.service"

                echo "   ✓ fc-agent installed and enabled"
              fi

              umount "$MOUNT_POINT"

              # 6. Verify template integrity
              echo "6. Verifying template integrity..."
              e2fsck -f -y /var/firecracker/rootfs-template.ext4 || true
              echo "   ✓ Template filesystem check complete"

              # 7. Mark template as read-only (prevent accidental modification)
              chmod 444 /var/firecracker/rootfs-template.ext4
              echo "   ✓ Template marked read-only"

              # 8. Self-healing: Cleanup orphaned VM rootfs files
              echo "8. Cleaning up orphaned VM rootfs files..."
              ORPHANED_COUNT=0
              for rootfs in /var/firecracker/rootfs-vm-*.ext4; do
                if [ -f "$rootfs" ]; then
                  VM_ID=$(echo "$rootfs" | sed 's/.*rootfs-vm-\(.*\)\.ext4/\1/')
                  SOCKET="/run/aetherium/aetherium-vm-${VM_ID}.sock"

                  # If socket doesn't exist, rootfs is orphaned
                  if [ ! -S "$SOCKET" ]; then
                    echo "   Cleaning orphaned rootfs: $rootfs"
                    rm -f "$rootfs"
                    ORPHANED_COUNT=$((ORPHANED_COUNT + 1))
                  fi
                fi
              done

              if [ $ORPHANED_COUNT -eq 0 ]; then
                echo "   ✓ No orphaned rootfs files found"
              else
                echo "   ✓ Cleaned $ORPHANED_COUNT orphaned rootfs file(s)"
              fi

              echo ""
              echo "=== Initialization Complete ==="
              echo "Worker is ready to spawn VMs with per-VM rootfs isolation"
          securityContext:
            {{- toYaml .Values.worker.securityContext | nindent 12 }}
          volumeMounts:
            {{- if .Values.worker.volumes }}
            {{- range .Values.worker.volumes }}
            {{- if or (eq .name "dev-kvm") (eq .name "firecracker-assets") }}
            - name: {{ .name }}
              mountPath: {{ if eq .name "dev-kvm" }}/dev/kvm{{ else }}/var/firecracker{{ end }}
            {{- end }}
            {{- end }}
            {{- end }}

      containers:
        - name: worker
          image: {{ include "aetherium.worker.image" . }}
          imagePullPolicy: {{ .Values.worker.image.pullPolicy | default .Values.global.imagePullPolicy }}
          securityContext:
            {{- toYaml .Values.worker.securityContext | nindent 12 }}
          env:
            - name: CONFIG_PATH
              value: /etc/aetherium/config.yaml
            - name: NODE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: POSTGRES_HOST
              value: {{ include "aetherium.postgresql.host" . | quote }}
            - name: POSTGRES_PORT
              value: {{ include "aetherium.postgresql.port" . | quote }}
            - name: POSTGRES_DATABASE
              value: {{ .Values.postgresql.auth.database | default "aetherium" | quote }}
            {{- if not .Values.postgresql.enabled }}
            - name: POSTGRES_USER
              valueFrom:
                secretKeyRef:
                  name: {{ include "aetherium.secretName" . }}
                  key: POSTGRES_USER
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: {{ include "aetherium.secretName" . }}
                  key: POSTGRES_PASSWORD
            {{- else }}
            - name: POSTGRES_USER
              value: {{ .Values.postgresql.auth.username | quote }}
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: {{ .Release.Name }}-postgresql
                  key: password
            {{- end }}
            - name: REDIS_ADDR
              value: "{{ include "aetherium.redis.host" . }}:{{ include "aetherium.redis.port" . }}"
            - name: CONSUL_ADDR
              value: "{{ .Release.Name }}-consul.{{ .Release.Namespace }}.svc.cluster.local:8500"
            {{- with .Values.worker.env }}
            {{- toYaml . | nindent 12 }}
            {{- end }}
          volumeMounts:
            - name: config
              mountPath: /etc/aetherium
              readOnly: true
            {{- range .Values.worker.volumeMounts }}
            - name: {{ .name }}
              mountPath: {{ .mountPath }}
              {{- if .readOnly }}
              readOnly: {{ .readOnly }}
              {{- end }}
            {{- end }}
          {{- with .Values.worker.livenessProbe }}
          livenessProbe:
            {{- toYaml . | nindent 12 }}
          {{- end }}
          {{- with .Values.worker.readinessProbe }}
          readinessProbe:
            {{- toYaml . | nindent 12 }}
          {{- end }}
          resources:
            {{- toYaml .Values.worker.resources | nindent 12 }}
      volumes:
        - name: config
          configMap:
            name: {{ include "aetherium.configMapName" . }}
        {{- range .Values.worker.volumes }}
        - name: {{ .name }}
          {{- if .hostPath }}
          hostPath:
            path: {{ .hostPath.path }}
            type: {{ .hostPath.type | default "Directory" }}
          {{- else if .emptyDir }}
          emptyDir: {}
          {{- else if .persistentVolumeClaim }}
          persistentVolumeClaim:
            claimName: {{ .persistentVolumeClaim.claimName }}
          {{- end }}
        {{- end }}
      {{- with .Values.worker.nodeSelector }}
      nodeSelector:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.worker.affinity }}
      affinity:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.worker.tolerations }}
      tolerations:
        {{- toYaml . | nindent 8 }}
      {{- end }}
{{- end }}
